---
date:
  created: 2024-02-11
categories:
  - Project
tags:
  - tech
  - backups
  - organization
---
# Organization #1 - Raspberry Pi Backup Server

I have been working on getting more organized in work and life. When things are messy, I can get stressed out and do less things during the day. I think this will be the first post of several about my 2024 organization strategy. Mainly to serve as a knowledge dump for myself, but maybe someone out there will find it useful, painfully boring, or somewhere in between!

<!-- more -->

## Storage Media

I purchased an external 1TB SSD from Amazon, to store regular backups into. This should be more than enough storage for a long time, since my "base directory" was a smidge under 14GB. This folder contains all my photos, code projects, downloaded receipts and such, and all my old assignments from 3rd grade typing homework all the way up until grad school! So many of these files had no reason to be stored on my PC, but I didn't want to permanently delete everything - which is where SSK comes in. (SSK is the brand name of the drive, so let's just call it that.)

I had actually set up a backup server with my Raspberry Pi in the past using a hard drive disk as storage, but this was a long time ago so I had to re-learn everything. Hopefully this story serves as a personal guide for me if I ever need to do this again in the future.

Before touching the Raspberry Pi, I connected SSK to my PC and just did a simple drag-n-drop to copy all my files as their current state, so I at least started somewhere. After it finished a surprisingly quick backup, I then plugged it into the Pi.

## Connecting the Hardware

Of course, the Pi did not recognize that SSK was connected, so I had to programmatically mount the disk while logged into the Pi. (`df` shows which disks are mounted.) Some of these commands need permission elevation (e.g. `sudo`.) Write these data fields down, since they are all used later:

```shell
lsblk # block device location & partition
blkid # device UUID
fdisk -l # filesystem type
id # user and group id
```

And follow these steps to manually mount the drive:

```shell
mkdir -v /media/SSK-1TB # create a mount point for your disk
mount /dev/sda1 /media/SSK-1TB # manually mount the disk
  # replace `/dev/sda1` with your device partition
  # replace `SSK-1TB` with your custom device name
```

If the disk mounted successfully, you should be able to see your backed up files on that new directory, and then unmount the disk:

```shell
ls /media/SSK-1TB # list the files contained in the drive
umount /media/SSK-1TB # manually unmount the disk
```

Unfortunately, you would need to manually run the `mount` and `umount` commands every time the hardware was connected/disconnected, or the Pi was power cycled. To automatically mount the drive on startup, one needs to modify the `fstab` file.

```shell
sudo nano /etc/fstab
```

Add a new line with the following columns separated each by a space:

```
UUID=uuid mountPoint fileSystemType options dump pass
```

So for me, it looked like this:

```
UUID=1234-1234 /media/SSK-1TB exfat defaults 0 0
```

To apply changes, I did a simple reboot of my machine:

```shell
sudo reboot 0
```

For me, SSK was factory formatted as the `exfat` file system format, which brings around other problems in Ubuntu. I did not have permissions to create, modify, or delete files on SSK while it was mounted to my Pi. After some frustrating research, I figured out the issue thanks to a [Ubuntu Community post](https://help.ubuntu.com/community/Fstab). Luckily, the fix was very easy. I needed to mount the disk specifying a user and group ID in the `options` column - which can be obtained using the `id` command. So in the end, my new line in `fstab` looked like this, where `1000` was my user and group ID:

```
UUID=1234-1234 /media/SSK-1TB exfat defaults,uid=1000,gid=1000 0 0
```

After implementing this change and doing another reboot, my disk was mounted successfully with read and write access! Now, for the fun part.

## Actually Working

I used `rsync` for creating and updating my backups. After getting an understanding of how it works, the code is incredibly easy. Here is a minimum example of what I am doing:

```shell
# sync
# For creating an exact mirror of my home directory
rsync -av --delete "$src" "$host:/media/SSK-1TB/mirror/"
```

```shell
# backup
# For creating a daily snapshot of my home directory
rsync -av "$src" "$host:/media/SSK-1TB/backups/$(date +%Y-%m-%d)/"
```

> **WARNING!** The first time you run these scripts, it has to initially copy over every file in the source directory. Depending on the total file size, this could take a long time! (It took over an hour to run the sync script.) Also, make sure your storage device has enough storage available for the backup!

For these scripts, you can run manually (using the `-n` flag for a dry run) or automate them as a CRON job. Of course, we are here to automate as much as possible, so open the crontab with this command:

```shell
crontab -e
```

Then, add a new line with your CRON schedule (I like using [crontab.guru](https://crontab.guru/) for this) and the command. Probably not required, but I always like to set my working directory to the location of the script before running it, to minimize any kind of logic bugs. I also like to capture the script output in a log file, to get some insight into what happened. The `cd ... && ./script >> output.log` pattern is a neat trick I picked up for this kind of thing. I wanted my mirroring script to run twice a day, at 8 AM and 8 PM. I want to invoke the backup snapshot script manually only, but it could be automated with a similar line in the crontab.

```
0 8,20 * * * cd /home/nic/Documents/Nicolas && ./sync >> sync.log
```

> **Note:** The backup script will automatically run at 8 AM and 8 PM if my PC is *turned on*. So, there may be days where it runs once or not at all, but can be invoked manually of course.